{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf52421",
   "metadata": {},
   "source": [
    "## Security Camera - Using YOLO to Detect Objects And for Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd79bd2",
   "metadata": {},
   "source": [
    "### Import Laberies and define application variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da2a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import cvlib as cv\n",
    "\n",
    "from collections import deque\n",
    "from timeit import default_timer as timer\n",
    "from cvlib.object_detection import draw_bbox\n",
    "\n",
    "# Catch frame from webcam\n",
    "camera = cv2.VideoCapture(1)\n",
    "\n",
    "# Scale to decrease the frame size\n",
    "SCALE = 4\n",
    "\n",
    "# Variable define timer of checking tracking status\n",
    "CHECKER = 10\n",
    "\n",
    "# Initializing deque object for center points of the detected object\n",
    "points = deque(maxlen=50)\n",
    "\n",
    "# Define variables for hight and width shape of the frames\n",
    "HEIGH, WIDTH = 400, 800 \n",
    "\n",
    "# Define objects boundaries size\n",
    "MIN_OBJECT_AREA = 1000\n",
    "MAX_OBJECT_AREA = 10000\n",
    "\n",
    "# Define the tresh hold of the masks\n",
    "DIFF_TRESH_HOLD = 10  # Should be low\n",
    "MASK_TRESH_HOLD = 100 # Should be high\n",
    "\n",
    "# Create backgroung of the main frame\n",
    "foregroundModel = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Define tracker dictionary\n",
    "tracker_dict = { 'csrt': cv2.legacy.TrackerCSRT_create,\n",
    "                 'kcf' : cv2.legacy.TrackerKCF_create,\n",
    "                 'boosting' : cv2.legacy.TrackerMOSSE_create,\n",
    "                 'mil': cv2.legacy.TrackerMIL_create,\n",
    "                 'tld': cv2.legacy.TrackerTLD_create,\n",
    "                 'medianflow': cv2.legacy.TrackerMedianFlow_create,\n",
    "                 'mosse':cv2.legacy.TrackerMOSSE_create}\n",
    "\n",
    "# Define the background\n",
    "last_frame = np.zeros((int(HEIGH/SCALE), int(WIDTH/SCALE), 3) , np.uint8)\n",
    "\n",
    "# Variable store the system status of tracking or not tracking\n",
    "tracking_on = False\n",
    "    \n",
    "# Initializing variable\n",
    "colors_labels = []\n",
    "\n",
    "# Restart timer for FPS\n",
    "fps_start = timer()    \n",
    "\n",
    "tracking_status = \"End Tracking\"\n",
    "\n",
    "# Variable counting how many time we are trying to detect objects\n",
    "counter_frames_predictions = 0\n",
    "\n",
    "# Variable counting how many time we are tracking after the objects\n",
    "frames_tracking_counter = 0\n",
    "\n",
    "# Variable counting how many object we detected in every iteration\n",
    "object_detected_counter = 0\n",
    "\n",
    "# Variable counting how many times we read frames\n",
    "frames_reading_counter = 0\n",
    "num_of_detections = 0\n",
    "last_detections = 0\n",
    "counter_fps = 0\n",
    "FPS = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559d450",
   "metadata": {},
   "source": [
    "### Define all application functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc92e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function return 3-Dimension frame\n",
    "def expands_dimensions(frame):\n",
    "    \n",
    "    new_image = np.zeros((frame.shape[0], frame.shape[1], 3), np.uint8)\n",
    "    new_image[:, :, 0] = frame\n",
    "    new_image[:, :, 1] = frame\n",
    "    new_image[:, :, 2] = frame\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "# Convert frame from rgb to gray\n",
    "def gray_frame(frame_rgb):\n",
    "    \n",
    "    # Converting captured frame to GRAY by OpenCV function    \n",
    "    gray_frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    frame_gray = np.zeros(frame_rgb.shape, np.uint8)\n",
    "    frame_gray[:,:,0] = gray_frame\n",
    "    frame_gray[:,:,1] = gray_frame\n",
    "    frame_gray[:,:,2] = gray_frame\n",
    "    \n",
    "    return frame_gray\n",
    "\n",
    "# This function remove the components that are smaller than praticular threshold\n",
    "def keepLargeComponents(image, treshold):\n",
    "    \n",
    "    frame = np.zeros(image.shape) < 0 # boolean array\n",
    "    unique_labels = np.unique(image.flatten()) # find out every unique value that is actually a label \n",
    "    \n",
    "    for label in unique_labels:\n",
    "        if label == 0: # background\n",
    "            pass\n",
    "        else:\n",
    "            img = (image == label) # save the component\n",
    "            if treshold < np.sum(img):\n",
    "                frame = frame | img # save all the components\n",
    "                \n",
    "    return np.float32(255*frame)\n",
    "\n",
    "# Function define the mask\n",
    "def mask(frame_rgb, background):\n",
    "    \n",
    "    # Converting captured frame to GRAY by OpenCV function    \n",
    "    frame_gray = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Create one more frame with Gaussian blur\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (25, 25), 0)  \n",
    "\n",
    "    # Converting captured frame to GRAY by OpenCV function        \n",
    "    background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create one more frame with Gaussian blur\n",
    "    background = cv2.GaussianBlur(background, (25, 25), 0)    \n",
    "    \n",
    "    # Return mask to detect change between two frames   \n",
    "    abs_diff = cv2.absdiff(frame_gray, background)\n",
    "    \n",
    "    # Function exclude values that ara more than treshhold = 15 0 and more than 255\n",
    "    _, mask = cv2.threshold(abs_diff, 9, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    dilated_mask = cv2.dilate(mask, None, iterations = 5)\n",
    "\n",
    "    # Expend mask dimension to 3 dimension\n",
    "    mask_frame = expands_dimensions(dilated_mask)        \n",
    "\n",
    "    return mask_frame\n",
    "\n",
    "def mask_tracking(frame_RGB, last_frame):\n",
    "    \n",
    "    # Converting captured frame to GRAY by OpenCV function    \n",
    "    frame_gray = cv2.cvtColor(frame_RGB, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Converting captured frame to GRAY by OpenCV function        \n",
    "    last_frame = cv2.cvtColor(last_frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    # Return mask to detect change between two frames   \n",
    "    abs_diff = cv2.absdiff(frame_gray, last_frame)\n",
    "    \n",
    "    # Function exclude values that ara more than treshhold = 15 0 and more than 255\n",
    "    _, abs_diff_mask = cv2.threshold(abs_diff, DIFF_TRESH_HOLD, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Expend mask dimension to 3 dimension\n",
    "    mask_frame = expands_dimensions(abs_diff_mask)        \n",
    "    \n",
    "    return mask_frame\n",
    "\n",
    "# Function create a mask with connectedComponents\n",
    "def cv_mask(frame_rgb, last_frame):\n",
    "       \n",
    "    # Apply the frame to forground model\n",
    "    foreground_mask = foregroundModel.apply(frame_rgb)\n",
    "    \n",
    "    # Reduce noises\n",
    "    structuring_element = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "    foreground_mask = cv2.morphologyEx(np.float32(foreground_mask), cv2.MORPH_OPEN, structuring_element)\n",
    "    \n",
    "    # Find out connected components and keep only the large components\n",
    "    num_labels, image_labels = cv2.connectedComponents(np.array(0<foreground_mask, np.uint8))\n",
    "    \n",
    "    # Return components larger than threshold\n",
    "    foreground_mask = keepLargeComponents(image_labels, treshold=10) \n",
    "    \n",
    "    # Using 'clip' function to exclude values that are less than 0 and more than 255\n",
    "    foreground_mask = np.clip(foreground_mask, 0, 255).astype(np.uint8) \n",
    "    \n",
    "    # Function exclude values that ara more than treshhold = 15 0 and more than 255\n",
    "    _, foreground_mask = cv2.threshold(foreground_mask, 5, 255, cv2.THRESH_BINARY)   \n",
    "    \n",
    "    # Converting output feature map from Tensor to Numpy array\n",
    "    foreground_mask = foreground_mask[:, :, np.newaxis]  \n",
    "    \n",
    "    foreground_mask = np.repeat(foreground_mask, 3, axis=2) \n",
    "        \n",
    "    return foreground_mask\n",
    "    \n",
    "# Function create 3 frames from the frame we read\n",
    "def preproccess_frames(frame, last_frame):\n",
    "    \n",
    "    # Define small sizes\n",
    "    heigh, width = int(HEIGH/SCALE), int(WIDTH/SCALE)\n",
    "    \n",
    "    # Resize the main frame to (WIDTH, HEIGH) shape\n",
    "    frame = cv2.resize(frame, (WIDTH, HEIGH))\n",
    "        \n",
    "    # Copy frame to work with deffrent variable\n",
    "    frame_rgb = cv2.resize(frame, (width, heigh))\n",
    "    \n",
    "    # Return mask for detection \n",
    "    frame_mask = cv_mask(frame_rgb, last_frame)\n",
    "    \n",
    "    # Return mask for tracking\n",
    "    tracking_mask = mask_tracking(frame_rgb, last_frame)\n",
    "    \n",
    "    # Define last frame\n",
    "    last_frame = frame_rgb.copy()\n",
    "    \n",
    "    return frame, frame_rgb, tracking_mask, frame_mask, last_frame\n",
    "\n",
    "# Function manage the frames reader variables like efps etc'\n",
    "def reader_manger(FPS, fps_start, counter_fps, tracking_on):\n",
    "       \n",
    "    # Variable says if keep reading frame or quit\n",
    "    quit = False\n",
    "\n",
    "    # Stopping the timer for FPS\n",
    "    fps_stop = timer()\n",
    "\n",
    "    # Print FPS every 1 second\n",
    "    if 1.0 <= fps_stop - fps_start:\n",
    "\n",
    "        # Define FPS\n",
    "        FPS = counter_fps\n",
    "\n",
    "        # Reset FPS counter\n",
    "        counter_fps = 0\n",
    "\n",
    "        # Restart timer for FPS\n",
    "        fps_start = timer()       \n",
    "\n",
    "    # Function waits for key to be pressed    \n",
    "    key = cv2.waitKey(1) % 256\n",
    "\n",
    "    # If 'n' is pressed, we catchs the frame and define it as the background\n",
    "    if key == ord('n'):\n",
    "        tracking_on = False\n",
    "\n",
    "    # If 'q' key is pressed then quit from app\n",
    "    if key == ord('q'):\n",
    "        quit = True   \n",
    "\n",
    "    # Putting text with label on the current BGR frame\n",
    "    #cv2.putText(frame, str(FPS), (WIDTH - 70, HEIGH - 30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2)  \n",
    "\n",
    "    return FPS, fps_start, counter_fps, tracking_on, quit\n",
    "\n",
    "# Function display the frames on the screen in one window\n",
    "def display_windows(frame, tracking_mask, frame_mask):   \n",
    "            \n",
    "    frame_mask = cv2.resize(frame_mask, (WIDTH, HEIGH))\n",
    "    # Create left window    \n",
    "    main_window = np.hstack((frame, frame_mask))\n",
    "    #main_window = np.hstack((frame, tracking_mask, frame_mask))\n",
    "\n",
    "    # Plotting all the frames in one window\n",
    "#     cv2.imshow(\"Main_Window\", main_window)  \n",
    "    # Plotting all the frames in one window\n",
    "    cv2.imshow(\"Main_Window\", frame)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053bc3a",
   "metadata": {},
   "source": [
    "### Define all the detection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "647e5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function manage the detection and return status and coordinates\n",
    "def detection_manager(frame, frame_rgb):\n",
    "\n",
    "    # Store the bounding boxes with the new coordinates in a list\n",
    "    boxes = []\n",
    "    \n",
    "    # Variable count how many objects we detect\n",
    "    num_of_objects = 0\n",
    "\n",
    "    # Function return all scores of model predictions\n",
    "    bounding_boxes, detected_labels, scores = cv.detect_common_objects(frame_rgb)\n",
    "\n",
    "    # Check if we succeeded to detect objects\n",
    "    if 0 < len(bounding_boxes):\n",
    "        \n",
    "        # Scaling the bounding boxes back to original main frame size\n",
    "        for box in bounding_boxes:\n",
    "\n",
    "            # Increase the objects counter\n",
    "            num_of_objects += 1\n",
    "\n",
    "            # Create new list of bounding boxes that fit to main frame size\n",
    "            (x_min, y_min, x_max, y_max) = [int(a) for a in box]\n",
    "            \n",
    "            # rectangle object contain x1, y1, box width, box height and not x,y max coordinates\n",
    "            (x_min, y_min, x_max, y_max) = x_min*SCALE, y_min*SCALE, (x_max)*SCALE, (y_max)*SCALE\n",
    "            \n",
    "            # bounding_boxes contain x1, y1, x2, y2, coordinates and not width and heigh\n",
    "            bounding_box = np.array([x_min, y_min, x_max, y_max])\n",
    "            boxes.append(bounding_box)\n",
    "\n",
    "            # Value means we start tracking after the objects\n",
    "            tracking_status = \"Start tracking\"\n",
    "    else:      \n",
    "        # Value means no tracking need and have to try detect again\n",
    "        tracking_status = \"End tracking\"\n",
    "            \n",
    "    return boxes, detected_labels, scores, num_of_objects, tracking_status\n",
    "\n",
    "# Function fit color to every label\n",
    "def set_labels_colors(detected_labels):\n",
    "    \n",
    "    colors_labels = []\n",
    "    labels = set(detected_labels)\n",
    "\n",
    "    for i in range(len(detected_labels)):\n",
    "\n",
    "        red = random.randint(0, 255)\n",
    "        blue = random.randint(0, 255)\n",
    "        green = random.randint(0, 255)\n",
    "\n",
    "        color = (blue, green, red)\n",
    "        label = detected_labels[i]\n",
    "\n",
    "        color_label = (label, color)\n",
    "\n",
    "        colors_labels.append(color_label)\n",
    "\n",
    "    return colors_labels\n",
    "\n",
    "def detected_object(frame_mask):\n",
    "    \n",
    "    # Count the number of detection\n",
    "    num_of_detected = 0\n",
    "    \n",
    "    mask = frame_mask.copy()\n",
    "    \n",
    "    # Converting captured frame to GRAY by OpenCV function    \n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Function return array of all contours we found\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sorted the contours and define the larger first\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    # Scan the contours list\n",
    "    for contour in contours:\n",
    "\n",
    "        # Return square area of the given contour\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "\n",
    "        # Find contours between MIN_OBJECT_AREA to MAX_OBJECT_AREA\n",
    "        if contour_area < MAX_OBJECT_AREA:\n",
    "            if MIN_OBJECT_AREA < contour_area:\n",
    "                \n",
    "                # Increase the number of objects\n",
    "                num_of_detected +=1\n",
    "                \n",
    "                # Get an approximate rectangle coordinates\n",
    "                (x_min, y_min, box_width, box_height) = cv2.boundingRect(contour)\n",
    "\n",
    "                # Drawing rectangle on the frame\n",
    "                frame_mask = cv2.rectangle(frame_mask, (x_min, y_min), (x_min +box_width, y_min +box_height), (0, 255, 0), 2)\n",
    "                \n",
    "                # Store the rectangle coordinates around the object\n",
    "                rectangle = np.array([x_min, y_min, box_width, box_height])\n",
    "            else:\n",
    "                # Contour is a sorted list so all the rest items irrelevant\n",
    "                break\n",
    "    \n",
    "    return num_of_detected, frame_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4fb68d",
   "metadata": {},
   "source": [
    "### Define all the tracking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05579bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function manages the start tracking case\n",
    "def start_tracking(frame, frame_rgb, bounding_boxes):\n",
    "    \n",
    "    # Initialize our tracker after the object\n",
    "    trackers = cv2.legacy.MultiTracker_create()\n",
    "    \n",
    "    # Update boxes list to the original main frame size scale\n",
    "    for box in bounding_boxes:\n",
    "\n",
    "        # Create rectangle that use us to tracking after the object and fit to main frame size\n",
    "        (x_min, y_min, x_max, y_max) = [int(a) for a in box]\n",
    "        \n",
    "        # rectangle object contain x1, y1, box width, box height and not x,y max coordinates\n",
    "        (x_min, y_min, x_max, y_max) = int(x_min/SCALE), int(y_min/SCALE), int((x_max)/SCALE), int((y_max)/SCALE)\n",
    "\n",
    "        # rectangle object contain x1, y1, box width, box height and not x,y max coordinates\n",
    "        rectangle = np.array([x_min, y_min, (x_max-x_min), (y_max-y_min)])\n",
    "\n",
    "        # Add the object to the trackers list\n",
    "        tracker_i = tracker_dict['csrt']()\n",
    "        trackers.add(tracker_i, frame_rgb, rectangle)\n",
    "\n",
    "    return trackers    \n",
    "\n",
    "# Function manage the tracking and return status and coordinates\n",
    "def tracking_manager(frame, frame_rgb, bounding_boxes, tracking_status, frames_tracking_counter):\n",
    "\n",
    "    # Initialize our tracker after the object\n",
    "    trackers = cv2.legacy.MultiTracker_create()\n",
    "    \n",
    "    # Check if there is still object to track after\n",
    "    if tracking_status == 'End Tracking':\n",
    "        \n",
    "        return frame, tracking_status, trackers\n",
    "            \n",
    "    # Check if we are just start the tracking or we are just keeping it\n",
    "    if tracking_status == 'Start tracking':\n",
    "          \n",
    "        trackers = start_tracking(frame, frame_rgb, bounding_boxes)      \n",
    "        \n",
    "        return frame, tracking_status, trackers\n",
    "        \n",
    "    return frame, trackers, tracking_status\n",
    "\n",
    "# Function manges the keep tracking case\n",
    "def keep_tracking_manager(frames_variables, tracking_variabels):\n",
    "\n",
    "    start_function = timer()\n",
    "    \n",
    "    # Extract the function variables\n",
    "    frame, frame_rgb, tracking_mask, frame_mask, frames_tracking_counter =  [var for var in frames_variables]     \n",
    "    trackers, tracking_status, tracking_on, detected_labels, colors_labels = [var for var in tracking_variabels]  \n",
    "    \n",
    "    # Get the bounding box from the frame\n",
    "    (success, bounding_boxes) = trackers.update(frame_rgb)  \n",
    "\n",
    "    # Strart\\Keep tracking\n",
    "    if success:      \n",
    "\n",
    "        # Variable is index of box in the bounding_boxes\n",
    "        index = 0 \n",
    "\n",
    "        for box in (bounding_boxes):        \n",
    "            \n",
    "            # Get the coordinates of the rectangle around the object\n",
    "            (x_min, y_min, w, h) = [int(a) for a in box]\n",
    "\n",
    "            # rectangle object contain x1, y1, box width, box height and not x,y max coordinates\n",
    "            (x_min, y_min, w, h) = x_min*SCALE, y_min*SCALE, (w)*SCALE, (h)*SCALE\n",
    "\n",
    "            # Check if coordinates is in the frame boundaries\n",
    "            if 0 <= x_min and x_min+w <= WIDTH and 0 <= y_min and y_min+h <= HEIGH:  \n",
    "\n",
    "                # Every 25 frames checking if tracking is still running after the object or not\n",
    "                if(frames_tracking_counter%25 == -1):  \n",
    "\n",
    "                    # Update tracking status\n",
    "                    tracking_status = \"End tracking\"\n",
    "\n",
    "                    # Initializes variable\n",
    "                    tracking_on = False \n",
    "                    break\n",
    "\n",
    "                # Set tracking status ON\n",
    "                tracking_on = True       \n",
    "\n",
    "                # Update tracking status\n",
    "                tracking_status = \"Keep tracking\"      \n",
    "                \n",
    "                # Define the current label\n",
    "                label = detected_labels[index]\n",
    "\n",
    "                # Extract the label color\n",
    "                for element in colors_labels:\n",
    "                    if element[0] == label:\n",
    "                        Color = element[1]\n",
    "                    \n",
    "                # Drawing bounding box on the current BGR frame        \n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_min+w, y_min+h), Color, 2)\n",
    "\n",
    "                # Putting text with label on the current BGR frame\n",
    "                cv2.putText(frame, label, (x_min-5, y_min-5), cv2.FONT_HERSHEY_SIMPLEX, 1.5, Color, 2)  \n",
    "\n",
    "            # Increase index by 1\n",
    "            index += 1\n",
    "    end_function = timer()        \n",
    "\n",
    "    return frame, tracking_status, tracking_on, trackers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b880bc6d",
   "metadata": {},
   "source": [
    "### Reading framers from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c416cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop reading frame by frame and processing them\n",
    "while True:\n",
    "\n",
    "    # Increasing FPS counter\n",
    "    counter_fps += 1\n",
    "        \n",
    "    # Increase tracking counter\n",
    "    frames_reading_counter += 1\n",
    "    \n",
    "    # Capturing frames one-by-one from camera\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    # If the frame was not retrieved then we break the loop\n",
    "    if not ret or frame is None:\n",
    "        break        \n",
    "    \n",
    "    # Define the fps of the loop using cv2 function\n",
    "    camera_fps = (int(camera.get(cv2.CAP_PROP_FPS)))\n",
    "        \n",
    "    # Function return 3 diffrent kind of frames\n",
    "    frame, frame_rgb, tracking_mask, frame_mask, last_frame = preproccess_frames(frame, last_frame)\n",
    "\n",
    "    # Counting the numb of objects in the frame\n",
    "    num_of_detections, frame_mask = detected_object(frame_mask)  \n",
    "    \n",
    "    if 0 < np.sum(frame_mask):\n",
    "\n",
    "        # If the number of objects has change we start detection state again\n",
    "        if last_detections < num_of_detections:\n",
    "\n",
    "            tracking_on = False\n",
    "            tracking_status == \"End tracking\"\n",
    "\n",
    "        # Treats objects tracking\n",
    "        if tracking_on == True:\n",
    "\n",
    "            # Putting text with number of derection on the current mask frame\n",
    "            cv2.putText(frame_mask, \"Last Detection: \"+ str(last_detections), (10, 15), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)  \n",
    "            cv2.putText(frame_mask, \"Last Detection: \"+ str(num_of_detections), (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            # Increase tracking counter\n",
    "            frames_tracking_counter += 1\n",
    "\n",
    "            # Compres the keep_tracking_manager variables\n",
    "            frames_variables = [frame, frame_rgb, tracking_mask, frame_mask, frames_tracking_counter]   \n",
    "            tracking_variabels = [trackers, tracking_status, tracking_on, detected_labels, colors_labels]\n",
    "\n",
    "            # Function manage the the part of the tracking   \n",
    "            frame, tracking_status, tracking_on, tracker = keep_tracking_manager(frames_variables, tracking_variabels)\n",
    "\n",
    "            # Update tracking status for the next iterate\n",
    "            if tracking_status == \"End tracking\":\n",
    "                tracking_on = False \n",
    "            if tracking_status == \"Keep tracking\":\n",
    "                tracking_on = True\n",
    "\n",
    "        # End of tracking_on - Treats objects detection\n",
    "        else:\n",
    "\n",
    "            # Increase prediction counter\n",
    "            counter_frames_predictions += 1\n",
    "\n",
    "            # Counting the numb of objects in the frame\n",
    "            last_detections, frame_mask = detected_object(frame_mask)\n",
    "\n",
    "            # Function manage the detection part and return coordinates of drawing   \n",
    "            bounding_boxes, detected_labels, scores, object_detected_counter, tracking_status = detection_manager(frame, frame_rgb)\n",
    "\n",
    "            # Function return set of (label,color)\n",
    "            colors_labels = set_labels_colors(detected_labels)\n",
    "\n",
    "            # Function draw boxes around the detected objects\n",
    "            frame = draw_bbox(frame, bounding_boxes, detected_labels, scores)\n",
    "\n",
    "            # Function manage the first part of the tracking and return coordinates of tracking    \n",
    "            frame, tracking_status, trackers = tracking_manager(frame, frame_rgb, bounding_boxes, tracking_status, frames_tracking_counter)\n",
    "\n",
    "            # Update tracking status to decide what next in the next iteration\n",
    "            if tracking_status == \"Start tracking\":\n",
    "                tracking_on = True\n",
    "            elif tracking_status == \"End tracking\":\n",
    "                tracking_on = False\n",
    "\n",
    "            \n",
    "    # Function manage the frames reader variables    \n",
    "    FPS, fps_start, counter_fps, tracking_on, quit = reader_manger(FPS, fps_start, counter_fps, tracking_on)\n",
    "        \n",
    "    # Display all frames in one window\n",
    "    display_windows(frame, tracking_mask, frame_mask)\n",
    "\n",
    "    # If quit is true so we stop read frames    \n",
    "    if quit == True:\n",
    "        break\n",
    "\n",
    "# Releasing camera\n",
    "camera.release()\n",
    "\n",
    "# Destroying all opened OpenCV windows\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df495b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
